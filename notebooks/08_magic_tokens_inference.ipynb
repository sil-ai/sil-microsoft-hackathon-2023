{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "08a5b7f0-c349-4078-82bf-d11be576027f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pickle, torch\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import Dropdown\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from transformers import TextDataset, DataCollatorForLanguageModeling\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import PreTrainedTokenizerFast, GPT2LMHeadModel, GPT2TokenizerFast, GPT2Tokenizer\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5d99504a-1037-4c88-a6fb-013f01b20ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model_folder = \"./out\"\n",
    "language_pair_staging_folder = \"../data/magic_token_folder/\"\n",
    "\n",
    "use_side_frozen_tokens = True\n",
    "if use_side_frozen_tokens:\n",
    "    num_magic_tokens = 1\n",
    "    trained_embeddings_pickle_file = os.path.join( language_pair_staging_folder, f\"magic_tokens_size_{num_magic_tokens}.pickle\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e8f34c8c-bc99-4a5b-9ba3-ea9138f05b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folders ending with '_model': ['hebrew_model_step', 'bsb_model_step', 'greek_model', 'greek_model_step', 'target_model_step', 'bsb_model', 'target_model', 'hebrew_model']\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(trained_model_folder) and os.path.isdir(trained_model_folder):\n",
    "    # Get a list of all subfolders in language_pair_staging_folder\n",
    "    subfolders = [folder for folder in os.listdir(trained_model_folder) if os.path.isdir(os.path.join(trained_model_folder, folder))]\n",
    "\n",
    "    # Filter subfolders that end with \"_model\"\n",
    "    model_folders = [folder for folder in subfolders if folder.endswith(\"_model\") or folder.endswith( \"_model_step\" ) ]\n",
    "\n",
    "    # Print or use the list of model folders\n",
    "    print(\"Folders ending with '_model':\", model_folders)\n",
    "else:\n",
    "    print(f\"The folder '{trained_model_folder}' does not exist or is not a directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9eadf1f-1b47-40e2-a5d2-a4a90ac6a74f",
   "metadata": {},
   "source": [
    "# Inference\n",
    "copying code from https://www.kaggle.com/code/changyeop/how-to-fine-tune-gpt-2-for-beginners/notebook#Step-3.-Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "37f87a66-2b8a-487a-92f2-8d5181b7b85a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded previouse training from ../data/magic_token_folder/magic_tokens_size_1.pickle\n"
     ]
    }
   ],
   "source": [
    "def load_model(model_path):\n",
    "    model = GPT2LMHeadModel.from_pretrained(model_path)\n",
    "    return model\n",
    "\n",
    "\n",
    "def load_tokenizer(tokenizer_path):\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(tokenizer_path)\n",
    "    return tokenizer\n",
    "\n",
    "if use_side_frozen_tokens:\n",
    "    learned_magic_tokens = {}\n",
    "    if os.path.exists(trained_embeddings_pickle_file):\n",
    "        with open(trained_embeddings_pickle_file, 'rb') as file:\n",
    "            learned_magic_tokens = pickle.load(file)\n",
    "            print( f\"Loaded previouse training from {trained_embeddings_pickle_file}\" )\n",
    "    else:\n",
    "        print( f\"Previouse training not found at {trained_embeddings_pickle_file}\" )\n",
    "    \n",
    "    class MagicTokensEmbeddingPatch(nn.Module):\n",
    "        def __init__(self, tokenizer, other_embeddings ):\n",
    "            super().__init__()\n",
    "            self.tokenizer = tokenizer\n",
    "            self.other_embeddings = other_embeddings\n",
    "    \n",
    "        def forward( self, x ):\n",
    "            #print( f\"Called forward with x {x}\" )\n",
    "            batch_result_list = []\n",
    "            for batch in x:\n",
    "                #print( f\"batch is {batch}\" )\n",
    "                inputs_embeds_list = []\n",
    "                for id in batch:\n",
    "                    #print( f\"id is {id}\" )\n",
    "                    token_string = self.tokenizer.decode( [id] )\n",
    "                    #print( f\"token_string is {token_string}\" )\n",
    "                    if token_string.startswith( '[' ) and token_string.endswith( ']' ):\n",
    "                        if token_string in learned_magic_tokens:\n",
    "                            inputs_embeds_list.append( learned_magic_tokens[token_string].detach() )\n",
    "                        else:\n",
    "                            print( f\"Don't have embedding for {token_string}\" )\n",
    "                            \n",
    "                    else:\n",
    "                        inputs_embeds_list.append( self.other_embeddings( torch.LongTensor([id]).to(x.device) )[0] )\n",
    "                        \n",
    "                inputs_embeds = torch.stack(inputs_embeds_list, dim=0)\n",
    "                batch_result_list.append(inputs_embeds)\n",
    "            return torch.stack(batch_result_list, dim=0)\n",
    "\n",
    "def generate_text(sequence, max_length, model_path, top_k=1, tokenizer=None ): #top_k was 50\n",
    "    model = load_model(model_path)\n",
    "\n",
    "    if tokenizer is None:\n",
    "        tokenizer = load_tokenizer(model_path)\n",
    "    if use_side_frozen_tokens:\n",
    "        model.set_input_embeddings( MagicTokensEmbeddingPatch(tokenizer, model.get_input_embeddings()) )\n",
    "    \n",
    "    ids = tokenizer.encode(f'{sequence}', return_tensors='pt')\n",
    "    print( f\"Sequence ids {ids}\" )\n",
    "    final_outputs = model.generate(\n",
    "        ids,\n",
    "        do_sample=True,\n",
    "        max_length=max_length,\n",
    "        pad_token_id=model.config.eos_token_id,\n",
    "        top_k=top_k,\n",
    "        top_p=0.95,\n",
    "    )\n",
    "    print(tokenizer.decode(final_outputs[0], skip_special_tokens=False))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6d193e07-c6fa-45f0-825a-474b3945d322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select which model to test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47ffa1f65a82400587e23c632b33459d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(options=('hebrew_model_step', 'bsb_model_step', 'greek_model', 'greek_model_step', 'target_model_step…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "selected_model_dropdown = Dropdown(options=model_folders)\n",
    "print( \"Select which model to test\" )\n",
    "display(selected_model_dropdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7f459065-03b6-4b36-bd06-f5b8604facd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = load_tokenizer( os.path.join( trained_model_folder, selected_model_dropdown.value ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2cb6656f-8909-4e82-8f05-ea7d0d2e1f22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[GEN 1:1_a]'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode( [50257] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bae01730-add6-455b-9318-e0005840ae52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence ids tensor([[50259]])\n",
      "[GEN 1:2_a]  Now the earth was formless and void, and darkness was over the earth. The earth was filled with darkness and darkness was over the earth. The earth was filled with darkness and darkness was over the earth. The earth was filled with darkness and darkness was over the earth. The earth was filled with darkness and darkness was over the earth. The earth was filled with darkness and darkness was over the earth. The earth was filled with darkness and darkness was over the earth. The earth was filled with\n"
     ]
    }
   ],
   "source": [
    "#generate_text( \"[GEN 1:1_a]\", 100, os.path.join( trained_model_folder, selected_model_dropdown.value ), tokenizer=tokenizer )\n",
    "generate_text( \"[GEN 1:2_a]\", 100, \"gpt2\", tokenizer=tokenizer )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "38a0bfee-268c-4274-84b1-8cabd839e0a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence ids tensor([[96547, 96548]])\n",
      "[MAT 1:1_a] [MAT 1:1_b] He also sent his daughter, a beautiful virgin from Jerusalem, to the city where the king had sent him. She was twenty-three years old, and the daughter of King Darius, the daughter of Zadok the Jezreelite. She stayed there with the servants of King Darius, the master of the temple. When Queen Esther saw that his daughter was with the king, she was greatly alarmed. And the maidservant who stayed with the king said to the king,\n"
     ]
    }
   ],
   "source": [
    "generate_text( \"[MAT 1:1_a][MAT 1:1_b]\", 100, os.path.join( trained_model_folder, selected_model_dropdown.value ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c74a7d12-9967-44be-973f-590efa21daf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence ids tensor([[96547, 96548]])\n",
      "[MAT 1:1_a] [MAT 1:1_b] The Spirit of truth resides in Christ, which is to say nothing of falsehood. Who then is able to deliver the souls of wicked men? Let him who is rich be commended by God and commended by the saints. [GAL 6:5_a] [ACT 13:13_b] By this we understand that we are justified through Christ, that we are He who has been weighed out of the furnace, not in terms of flesh and blood, but with Christ, the power of life. [ROM 8:12_a] [ROM 7:7_b] By grace you have been strengthened in the\n"
     ]
    }
   ],
   "source": [
    "generate_text( \"[MAT 1:1_a][MAT 1:1_b]\", 100, os.path.join( trained_model_folder, selected_model_dropdown.value ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "46e9a569-00f8-4360-ab04-ba3b3fa70daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence ids tensor([[100045, 100046]])\n",
      "[LUK 1:1_a] [LUK 1:1_b] So Gideon sent messengers to the king of Israel at Ramoth-gilead: “We have found favor in your sight, for your servant is a man of valor from Kadesh-barnea.” “Go and look for him,” Elisha replied. [1SA 30:11_a] [NEH 6:11_b] So Gideon went to meet Elisha, who asked, “How long until the one I seek?” “In the past,” Gideon replied. [JHN 7:48_a] [JDG 19:17_b] “I have not had anyone like him present when I fought Aram-naharaim. What can I say?” Elisha asked. “That is enough,” replied Elisha. [GEN 19:28_a] [1SA 3:6_b] Then Gideon replied, “Your servant did not intend to fight, but to bring down the kingdom of Israel. What you are seeing is enough, for I have defeated them all.” [ISA 39:5_a] [2KI 8:14_b] So the king of Israel put him to the sword and said, “Let me see Gideon again tomorrow and take him down.” But Elisha said, “Later, if you will return, then tomorrow I will return and blow him down.” [JDG 10:11_a] [EST 7:1_b] So Gideon went to meet Elisha again and said, “You know that the LORD has delivered Israel all the more severely than the sword that I delivered you into your hand. How severely I have pronounced it!” “Do not be afraid,” replied Elisha. “Tomorrow morning I will carry out my vengeance on your master; then you can return to your master with honor.” [1SA 16:7_a] [2KI 5:26_a] [JDG 15:14_b] But the LORD said to him, “Go up and deliver Absalom into my hand, for tomorrow I will strike him down. So be on your guard against him, and I will act. May my master and all the people with him live. Then I will put an end to all his evil deeds.” [1KI 18:21_a] [2CH 23:17_b] [1SA 3:7_b] Elisha said to him, “If you shall strike down Absalom, O LORD, and I live, I will make you ruler over My people Israel. Then they will know that I am the LORD, even if they turn from their evil ways.” [MAT 27:50_a] [1CH 18:14_b] [1KI 18:46_b] izarrely, the king of Israel said to Elisha, “This is what the LORD has said: ‘Do not go with me, or I will put an end\n"
     ]
    }
   ],
   "source": [
    "generate_text( \"[LUK 1:1_a][LUK 1:1_b]\", 500, os.path.join( trained_model_folder, selected_model_dropdown.value ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f261e85a-e7dc-41c6-a2b2-72db40c17d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence ids tensor([[100045, 100046]])\n",
      "[LUK 1:1_a] [LUK 1:1_b] They shall not drink the cup offered by anyone during their Sabbaths, nor may their children drink it. [REV 20:4_a] [REV 2:9_b] In the Year of Jubilee, the priest must make atonement on behalf of the people for any of their transgressions. [REV 21:21_a] [REV 2:9_b] They are to take a large amount of money and give it to their relatives to be used for grain offerings or burnt offerings, as the LORD their God has commanded.’” [REV 2:18_a] [REV 21:27_b] On that same day the LORD said to Moses, [REV 9:5_b] [REV 20:3_b] “This is what the LORD of Hosts, the God of Israel, says: I will put an end to all indecency, both young and old, in the land of Egypt, because of the indecency of the daughters who were brought up with Me, and they were unfaithful to Me in all the abominations I had committed there. [REV 15:2_a] [REV 19:10_a] So I will make an end of them as the LORD has commanded; the Egyptians who were born in Egypt will come in and be fruitful and multiply in the land of Canaan, with great herds and flocks, in a land flowing with milk and honey, and in a land flowing with good soil, and I will give it to them as an inheritance in My inheritance. [REV 18:21_b] [REV 1:19_b] I will give them the land of Canaan as an inheritance and give it to their offspring after them, whom I delight in their offspring, so that they may possess it and multiply and flourish and multiply greatly. [REV 12:7_a] [REV 14:17_a] So I will cause the Canaan [PSA 63:7_a] [REV 21:10_a] [REV 14:12_b] and all the nations that have dwelt in the land of Egypt to bow down to Me in reverence and to bow down to Me in worship before Me as a man before the LORD their God. [REV 16:13_a] [REV 2:12_a] And I will place My Spirit upon them, which I will establish between Me and them to bless them and make atonement for their sins, to make atonement for their trespasses and make atonement for their iniquities. Then all the nations that have inhabited the land of Egypt will bow down to Me. [REV 2:6_a] [REV 21:1_b] [REV 13:7_a] I will make atonement before Me for all their transgressions and make atonement for their sins, so that they may receive an inheritance among them. [REV 19:11_a] [REV 19:11_b] [REV 13:7_a] And I will make atonement for their transgressions on Mount Sinai, because they are descendants of Jacob, and I will make atonement for their sins among them. [REV 16:2_a] [REV 2:9_b] [REV 16:11_b] The Israelites are to bow down before Me so that I will establish the boundaries and boundaries\n"
     ]
    }
   ],
   "source": [
    "generate_text( \"[LUK 1:1_a][LUK 1:1_b]\", 500, os.path.join( trained_model_folder, selected_model_dropdown.value ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0f604f26-5b8c-4fa4-8b2d-625078bec5bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence ids tensor([[1890, 1793,  523, 6151,  262,  995]])\n",
      "For God so loved the worldὁ  δὲ  ἀρχιερεὺς  καὶ  οἰκοδεσπότερον  καὶ  μόνον  ἀπὸ  τῆς  σκεύης  τοῦ  Θεοῦ. Ἰουδαίους  γὰρ  καὶ  οἱ  Ἰουδαίους  καὶ  οὐκ  ἠκολούθεια  καὶ  οἀκούθει\n"
     ]
    }
   ],
   "source": [
    "generate_text( \"For God so loved the world\", 200, os.path.join( trained_model_folder, selected_model_dropdown.value ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6529b1d9-11e5-46c8-b4fa-9f54fd2f3ef3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
