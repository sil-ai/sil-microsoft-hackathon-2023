{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1837c8df-217e-42e0-b867-8c2182f0a718",
   "metadata": {},
   "source": [
    "# This notebook trains just the magic token embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4966def-c57b-4c83-895e-6608679c6e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, torch\n",
    "from ipywidgets import Dropdown\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import SGD\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49b66a05-13ce-49f1-8fe4-85f6e17ba8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model_folder = \"./out\"\n",
    "language_pair_staging_folder = \"../data/magic_token_folder/\"\n",
    "num_magic_tokens = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a1f84b1-b997-44d2-9ec2-4b6d66f65be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select which model to train\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b79ba66ae3ca41c388a291bc1b7b36b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(options=('hebrew_model_step', 'bsb_model_step', 'greek_model', 'greek_model_step', 'target_model_step…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "subfolders = [folder for folder in os.listdir(trained_model_folder) if os.path.isdir(os.path.join(trained_model_folder, folder))]\n",
    "model_folders = [folder for folder in subfolders if folder.endswith(\"_model\") or folder.endswith( \"_model_step\" ) ]\n",
    "selected_model_dropdown = Dropdown(options=model_folders)\n",
    "print( \"Select which model to train\" )\n",
    "display(selected_model_dropdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98badf61-46fa-4127-bb26-1491d0c4d2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path):\n",
    "    model = GPT2LMHeadModel.from_pretrained(model_path)\n",
    "    return model\n",
    "\n",
    "\n",
    "def load_tokenizer(tokenizer_path):\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(tokenizer_path)\n",
    "    return tokenizer\n",
    "\n",
    "\n",
    "def grab_line_from_file( file, index ):\n",
    "    n = 0\n",
    "    with open( file, \"rt\" ) as fin:\n",
    "        for line in fin:\n",
    "            if n == index:\n",
    "                return line.strip()\n",
    "            n += 1\n",
    "\n",
    "def get_index_from_training_file( index ):\n",
    "    language = selected_model_dropdown.value.replace( \"_model\", \"\" ).replace( \"_step\", \"\" )\n",
    "    training_file = os.path.join( language_pair_staging_folder, \n",
    "                                 f\"train_{language}.txt\" )\n",
    "    return grab_line_from_file( training_file, index )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11e1eff2-7287-4298-be19-af9a2601f2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = load_tokenizer( os.path.join( trained_model_folder, selected_model_dropdown.value ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d5d417c4-b26c-4ec1-ba55-5a2ed6a39837",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model( os.path.join( trained_model_folder, selected_model_dropdown.value ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f385f9-5649-44ab-b922-d93dfe0bd6ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "verse_number = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0b6b9a61-4723-420d-a9d4-cebed9230e2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Working on verse [GEN 13:14_a][GEN 13:14_b] After Lot had departed, the LORD said to Abram, “Now lift up your eyes from the place where you are, and look to the north and south and east and west,\n",
      "\n",
      "0: After Lot had gone\n",
      "1: After Lot had gone\n",
      "2: After Lot had gone\n",
      "3: After Lot had gone\n",
      "4: After Lot had gone\n",
      "5: For\n",
      "6: After Lot had departed, Lot\n",
      "7: After Lot had departed, Lot\n",
      "8: After Lot had departed, Lot\n",
      "9: After Lot had departed, Lot\n",
      "10: After Lot had departed, the LORD appeared\n",
      "11: After Lot had gone\n",
      "12: After Lot had departed, the LORD appeared\n",
      "13: After Lot had departed, the LORD appeared\n",
      "14: After Lot had departed, the LORD appeared\n",
      "15: After Lot had departed, the LORD appeared\n",
      "16: After Lot had departed, the LORD appeared\n",
      "17: After Lot had departed, the LORD appeared\n",
      "18: After Lot had gone\n",
      "19: After this\n",
      "20: After Lot had departed, the LORD appeared\n",
      "21: After Lot had departed, the LORD appeared\n",
      "22: After Lot had departed, the LORD appeared\n",
      "23: After Lot had departed, the LORD appeared\n",
      "24: After Lot had departed, the LORD appeared\n",
      "25: After Lot had departed, the LORD appeared\n",
      "26: After Lot had departed, the LORD appeared\n",
      "27: After Lot had departed, the LORD appeared\n",
      "28: After Lot had departed, the LORD appeared\n",
      "29: After Lot had departed, the LORD appeared\n",
      "30: After Lot had departed, the LORD said to Abram, ��Get\n",
      "31: After Lot had departed, the LORD said to Abram, ��Get\n",
      "32: After Lot had departed, the LORD said to Abram, ��Get\n",
      "33: After Lot had departed, the LORD said to Abram, ��Get\n",
      "34: After Lot had departed, the LORD said to Abram, ��Get\n",
      "35: After Lot had departed, the LORD said to Abram, ��Get\n",
      "36: After Lot had departed, the LORD said to Abram, ��Get\n",
      "37: After Lot had departed, the LORD said to Abram, ��Get\n",
      "38: After Lot had departed, the LORD said to Abram, ��Get\n",
      "39: After Lot had departed, the LORD said to Abram, ��Get\n",
      "40: After Lot had departed, the LORD said to Abram, ��Get\n",
      "41: After Lot had departed, the LORD said to Abram, ��Get\n",
      "42: After Lot had departed, the LORD said to Abram, ��Get\n",
      "43: After Lot had departed, the LORD said to Abram, ��Get\n",
      "44: After Lot had departed, the LORD said to Abram, ��Get\n",
      "45: After Lot had departed, the LORD said to Abram, ��Get\n",
      "46: After Lot had departed, the LORD said to Abram, ��Get\n",
      "47: After Lot had departed, the LORD said to Abram, ��Get\n",
      "48: After Lot had departed, the LORD said to Abram, ��Get\n",
      "49: After Lot had departed, the LORD said to Abram, ��Get\n",
      "50: After Lot had departed, the LORD said to Abram, ��Get\n",
      "51: After Lot had departed, the LORD said to Abram, ��Get\n",
      "52: After Lot had departed, the LORD said to Abram, ��Get\n",
      "53: After Lot had departed, the LORD said to Abram, ��Get\n",
      "54: After Lot had departed, the LORD said to Abram, ��Get\n",
      "55: After Lot had departed, the LORD said to Abram, ��Get\n",
      "56: After Lot had departed, the LORD said to Abram, ��Get\n",
      "57: After Lot had departed, the LORD said to Abram, ��Get\n",
      "58: After Lot had departed, the LORD said to Abram, ��Get\n",
      "59: After Lot had departed, the LORD said to Abram, ��Get\n",
      "60: After Lot had departed, the LORD said to Abram, ��Do\n",
      "61: After Lot had departed, the LORD said to Abram, ��You\n",
      "62: After Lot had departed, the LORD said to Abram, ��Now Abram\n",
      "63: After Lot had departed, the LORD said to Abram, ��You\n",
      "64: After Lot had departed, the LORD said to Abram, ��Now Abram\n",
      "65: After Lot had departed, the LORD said to Abram, ��Now you\n",
      "66: After Lot had departed, the LORD said to Abram, ��Now you\n",
      "67: After Lot had departed, the LORD said to Abram, ��Do\n",
      "68: After Lot had gone\n",
      "69: After Lot had departed, the LORD said to Abram, ��Now you\n",
      "70: After Lot had departed, the LORD said to Abram, ��Now you\n",
      "71: After Lot had departed, the LORD said to Abram, ��Do\n",
      "72: After Lot had departed, the LORD said to Abram, ��Now you\n",
      "73: After Lot had departed, the LORD said to Abram, ��Now you\n",
      "74: After Lot had departed, the LORD said to Abram, ��Now you\n",
      "75: After they\n",
      "76: After Lot had departed, the LORD said to Abram, ��Get\n",
      "77: After Lot had departed, the LORD said to Abram, ��Now you\n",
      "78: After Lot had departed, the LORD said to Abram, ��Now you\n",
      "79: After Lot had departed, the men\n",
      "80: After Lot had departed, the LORD said to Abram, ��Now you\n",
      "81: After Lot had departed, the LORD said to Abram, ��Get\n",
      "82: After Lot had departed, the LORD said to Abram, ��Now you\n",
      "83: After Lot had departed, the LORD said to Abram, ��Now you\n",
      "84: After Lot had departed, the LORD said to Abram, ��Now you\n",
      "85: After Lot had departed, the men\n",
      "86: After Lot had departed, the LORD said to Abram, ��Get\n",
      "87: After Lot had departed, the LORD said to Abram, ��Now you\n",
      "88: After Lot had departed, the LORD said to Abram, ��Now you\n",
      "89: After Lot had departed, the LORD said to Abram, ��Now you\n",
      "90: All\n",
      "91: After Lot had gone\n",
      "92: After Lot had gone\n",
      "93: After Lot had departed, the LORD said to Abram, ��Get\n",
      "94: After Lot had departed, the LORD said to Abram, ��Get\n",
      "95: After Lot had departed, the LORD said to Abram, ��Now you\n",
      "96: After Lot had departed, the LORD appeared\n",
      "97: After Lot had departed, the LORD said to Abram, ��Now you\n",
      "98: After Lot had departed, the LORD said to Abram, ��Now you\n",
      "99: After Lot had departed, the LORD said to Abram, ��Get\n",
      "\n",
      "Working on verse [GEN 13:15_a][GEN 13:15_b] for all the land that you see, I will give to you and your offspring forever.\n",
      "\n",
      "0: And\n",
      "1: And\n",
      "2: and\n",
      "3: and\n",
      "4: for the\n",
      "5: for the\n",
      "6: for the\n",
      "7: for the\n",
      "8: for the\n",
      "9: for the\n",
      "10: for the\n",
      "11: for the\n",
      "12: for the\n",
      "13: for the\n",
      "14: for the\n",
      "15: for the\n",
      "16: for the\n",
      "17: for the\n",
      "18: for the\n",
      "19: for the\n",
      "20: for the\n",
      "21: the\n",
      "22: for the\n",
      "23: for the\n",
      "24: for the\n",
      "25: for the\n",
      "26: for the\n",
      "27: for the\n",
      "28: for the\n",
      "29: for all the work\n",
      "30: for all the work\n",
      "31: for all the work\n",
      "32: for all the work\n",
      "33: for all the work\n",
      "34: for all the articles\n",
      "35: for all the articles\n",
      "36: for all the articles\n",
      "37: for all the land of\n",
      "38: for all the land of\n",
      "39: for the\n",
      "40: for all the land of\n",
      "41: for all the land of\n",
      "42: for all the land of\n",
      "43: for all the land of\n",
      "44: for all the nations\n",
      "45: for all the land of\n",
      "46: for all the land of\n",
      "47: for all the land of\n",
      "48: for all the land of\n",
      "49: for all the land that the\n",
      "50: for the\n",
      "51: for all the land of\n",
      "52: for all the land that the\n",
      "53: for all the land that the\n",
      "54: for all the land that the\n",
      "55: for all the nations\n",
      "56: for all the land that the\n",
      "57: for all the land that the\n",
      "58: for all the land that the\n",
      "59: for all the land that the\n",
      "60: for all the land that the\n",
      "61: for all the land that the\n",
      "62: for all the land that the\n",
      "63: for all the land that the\n",
      "64: for all the land that the\n",
      "65: for all the land that the\n",
      "66: for all the land that the\n",
      "67: for all the evil\n",
      "68: so\n",
      "69: for all the land that the\n",
      "70: for all the land that the\n",
      "71: for all the land that the\n",
      "72: for all the land that the\n",
      "73: for all the land that the\n",
      "74:  for\n",
      "75: for the\n",
      "76: for all the land that the\n",
      "77: for all the land that the\n",
      "78: for all the land that the\n",
      "79: for all the land that the\n",
      "80: for all the land that the\n",
      "81: for all the land that you are\n",
      "82: for all the land that the\n",
      "83: for all the land that you are\n",
      "84: for all the land that the\n",
      "85: for all the land that you are\n",
      "86: for all the land is\n",
      "87: for all the land that you are\n",
      "88: for all the land that you are\n",
      "89: for all the land is\n",
      "90: for all the land that you are\n",
      "91: for all the land that you are\n",
      "92: for a\n",
      "93: for all the land that you are\n",
      "94: for all the land that you see is\n",
      "95: for a\n",
      "96: for all the idols\n",
      "97: for all the land that you are\n",
      "98: for all the land that you see is\n",
      "99:  for\n",
      "\n",
      "Working on verse [GEN 13:16_a][GEN 13:16_b] I will make your offspring like the dust of the earth, so that if one could count the dust of the earth, then your offspring could be counted.\n",
      "\n",
      "0: And\n",
      "1: And\n",
      "2: I will make you\n",
      "3: I will make you\n",
      "4: I will make you\n",
      "5: I will make you\n",
      "6: I will make you\n",
      "7: I will make you\n",
      "8: I will make you\n",
      "9: I will make you\n",
      "10: I will make you\n",
      "11: I will make you\n",
      "12: I will make you\n",
      "13: I will make you\n",
      "14: I will make you\n",
      "15: I will make you\n",
      "16: I will make you\n",
      "17: I will make you\n",
      "18: I will make you\n",
      "19: I will make you\n",
      "20: I will make you\n",
      "21: I will make you\n",
      "22: I will make you\n",
      "23: I will make you\n",
      "24: I will make you\n",
      "25: I will make you\n",
      "26: I will make you\n",
      "27: I will make you\n",
      "28: I will make you\n",
      "29: I will make you\n",
      "30: I will make you\n",
      "31: I will make you\n",
      "32: I will make you\n",
      "33: I will make you\n",
      "34: I will make you\n",
      "35: I will make you\n",
      "36: I will make you\n",
      "37: I will make you\n",
      "38: I will make you\n",
      "39: I will make you\n",
      "40: I will make you\n",
      "41: I will make you\n",
      "42: I will make you\n",
      "43: And\n",
      "44: I will make you\n",
      "45: I will make you\n",
      "46: I will make you\n",
      "47: I will make you\n",
      "48: I will make you\n",
      "49: I will make you\n",
      "50: I will make you\n",
      "51: I will make you\n",
      "52: I will make you\n",
      "53: I will make you\n",
      "54: I will make you\n",
      "55: I will make you\n",
      "56: I will make you\n",
      "57: I will make you\n",
      "58: I will make you\n",
      "59: I will make you\n",
      "60: I will make your walls\n",
      "61: I will make you\n",
      "62: I will make you\n",
      "63: I will make your walls\n",
      "64: I will make you\n",
      "65: I will make you\n",
      "66: I will make your walls\n",
      "67: I will make you\n",
      "68: I will make your walls\n",
      "69: I will make you\n",
      "70: I will make you\n",
      "71: I will make your walls\n",
      "72: I will make you\n",
      "73: I will make your walls\n",
      "74: I will make you\n",
      "75: I will make your walls\n",
      "76: I will make you\n",
      "77: I will make your walls\n",
      "78: I will make you\n",
      "79: I will make your walls\n",
      "80: I will make you\n",
      "81: I will make your walls\n",
      "82: I will make you\n",
      "83: I will make your walls\n",
      "84: I will make your walls\n",
      "85: I will make you\n",
      "86: I will make your walls\n",
      "87: You\n",
      "88: I will make you\n",
      "89: I will make you\n",
      "90: I will make your walls\n",
      "91: I will make your walls\n",
      "92: I will make your walls\n",
      "93: I will make you\n",
      "94: I will make your alt\n",
      "95: I will make your alt\n",
      "96: I will make your alt\n",
      "97: I will make your alt\n",
      "98: I will make your sons\n",
      "99: s\n",
      "\n",
      "Working on verse [GEN 13:17_a][GEN 13:17_b] Get up and walk around the land, through its length and breadth, for I will give it to you.”\n",
      "\n",
      "0: �\n",
      "1: �\n",
      "2: The\n",
      "3: The\n",
      "4: The\n",
      "5: Get up,\n",
      "6: Get up and go\n",
      "7: Get up and go\n",
      "8: Get up and go\n",
      "9: Get up and go\n",
      "10: Get up and go\n",
      "11: Get up and go\n",
      "12: Get up and go\n",
      "13: Get up and go\n",
      "14: Get up and go\n",
      "15: Get up and go\n",
      "16: Get up and go\n",
      "17: Get up and go\n",
      "18: Get up!\n",
      "19: Get up and go\n",
      "20: Get up and go\n",
      "21: Get up and walk!\n",
      "22: Get up and go\n",
      "23: Get up and walk!\n",
      "24:  starve\n",
      "25: Get up!\n",
      "26: Get up!\n",
      "27: Get up and go\n",
      "28: Get up and go\n",
      "29: Get up!\n",
      "30: Get up and go\n",
      "31: Get up and go\n",
      "32: Get up and walk!\n",
      "33: Get up and go\n",
      "34: Get up and walk!\n",
      "35: Get up and go\n",
      "36: Get up and walk!\n",
      "37: Get up and walk around the city\n",
      "38: Get up and go\n",
      "39: "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 50\u001b[0m\n\u001b[1;32m     48\u001b[0m result \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mforward( inputs_embeds \u001b[38;5;241m=\u001b[39m inputs_embeds )\u001b[38;5;66;03m#, attention_mask = attention_mask )\u001b[39;00m\n\u001b[1;32m     49\u001b[0m loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mcross_entropy( result\u001b[38;5;241m.\u001b[39mlogits[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m), target_tensor\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m) )\n\u001b[0;32m---> 50\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m probs \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39msoftmax(result\u001b[38;5;241m.\u001b[39mlogits[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m#sampled_token_id = torch.multinomial(probs, 1).item()\u001b[39;00m\n",
      "File \u001b[0;32m~/Sync/projects/tf_over/hackathon/microsoft_gpt_hackathon_2023/sil-microsoft-hackathon-2023/venv/lib/python3.10/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Sync/projects/tf_over/hackathon/microsoft_gpt_hackathon_2023/sil-microsoft-hackathon-2023/venv/lib/python3.10/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while get_index_from_training_file( verse_number ) != None:\n",
    "    verse = get_index_from_training_file( verse_number )\n",
    "    print( f\"\\n\\nWorking on verse {verse}\" )\n",
    "    #verse = \"Eat your\"\n",
    "    tokenized = tokenizer( verse )\n",
    "    \n",
    "    # mask_for_starting_magic_tokens = torch.zeros(len(tokenizer))\n",
    "    # mask_for_starting_magic_tokens[tokenized[\"input_ids\"][0]] = 1\n",
    "    # mask_for_starting_magic_tokens[tokenized[\"input_ids\"][1]] = 1\n",
    "    # mask_for_starting_magic_tokens = mask_for_starting_magic_tokens.unsqueeze(1)\n",
    "                                   \n",
    "    # control_weights = model.get_input_embeddings().weight\n",
    "    # model.set_input_embeddings( nn.Embedding.from_pretrained( control_weights ) )\n",
    "    # model.tie_weights()\n",
    "    \n",
    "    control_embeddings_weights = model.get_input_embeddings().weight.detach()\n",
    "    control_embeddings = nn.Embedding.from_pretrained( control_embeddings_weights )\n",
    "    \n",
    "    # learning_rate = 0.01\n",
    "    # optimizer = SGD( [\n",
    "    #     model.get_input_embeddings()(torch.LongTensor([tokenized[\"input_ids\"][0]])),\n",
    "    #     model.get_input_embeddings()(torch.LongTensor([tokenized[\"input_ids\"][1]]))], lr=learning_rate )\n",
    "    \n",
    "    # optimizer = SGD( [\n",
    "    #     model.get_input_embeddings().weight[ tokenized[\"input_ids\"][0] ],\n",
    "    #     model.get_input_embeddings().weight[ tokenized[\"input_ids\"][1] ],\n",
    "    # ], lr=learning_rate )\n",
    "    \n",
    "    slope = -.0001\n",
    "    \n",
    "    for run in range( 100 ):\n",
    "        model.zero_grad()\n",
    "        print( f\"\\n{run}: \", end='' )\n",
    "\n",
    "        found_problem = False\n",
    "        \n",
    "        for token_to_teach in range( num_magic_tokens, len(tokenized[\"input_ids\"]) ):\n",
    "    \n",
    "            input_ids = torch.LongTensor(tokenized[\"input_ids\"][:token_to_teach])\n",
    "            #attention_mask = torch.LongTensor(tokenized[\"attention_mask\"])\n",
    "            correct_token = tokenized[\"input_ids\"][token_to_teach]\n",
    "            target_tensor = torch.zeros(len(tokenizer))\n",
    "            target_tensor[correct_token] = 25.0\n",
    "    \n",
    "        \n",
    "            inputs_embeds = control_embeddings( input_ids )\n",
    "            inputs_embeds.requires_grad = True\n",
    "            result = model.forward( inputs_embeds = inputs_embeds )#, attention_mask = attention_mask )\n",
    "            loss = F.cross_entropy( result.logits[-1].unsqueeze(0), target_tensor.unsqueeze(0) )\n",
    "            loss.backward()\n",
    "        \n",
    "            probs = F.softmax(result.logits[-1], dim=-1)\n",
    "            #sampled_token_id = torch.multinomial(probs, 1).item()\n",
    "            sampled_token_id = torch.argmax(probs, dim=-1).item()\n",
    "            print(tokenizer.decode( [sampled_token_id] ), end='')\n",
    "        \n",
    "            # optimizer.step()\n",
    "            # masked_grad = mask_for_starting_magic_tokens*model.get_input_embeddings().weight.grad\n",
    "            # new_embeddings = nn.Embedding.from_pretrained( model.get_input_embeddings().weight + masked_grad * slope )\n",
    "            # model.set_input_embeddings( new_embeddings )\n",
    "            # model.tie_weights()\n",
    "            #model.get_input_embeddings().weight += (masked_grad * slope)\n",
    "            #control_weights += (masked_grad * slope)\n",
    "    \n",
    "            if sampled_token_id != correct_token:\n",
    "                found_problem = True\n",
    "                #print( f\"\\nbreaking because {tokenizer.decode([sampled_token_id])} != {tokenizer.decode([correct_token])}\" )\n",
    "                break\n",
    "        \n",
    "        new_inputs_embeds = inputs_embeds + (inputs_embeds.grad * slope)\n",
    "    \n",
    "        for token_i in range(num_magic_tokens):\n",
    "            control_embeddings_weights[tokenized[\"input_ids\"][token_i]] = new_inputs_embeds[token_i].detach()\n",
    "        control_embeddings = nn.Embedding.from_pretrained( control_embeddings_weights )\n",
    "\n",
    "        if not found_problem: break\n",
    "    \n",
    "    model.set_input_embeddings(control_embeddings)\n",
    "    model.tie_weights()\n",
    "\n",
    "    verse_number += 1\n",
    "    \n",
    "#correct_logits = \n",
    "# tokenized_torch = \n",
    "# output = model(tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "30ffcb58-fd0f-40c3-b1d8-dc4fbef87588",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_input_embeddings(control_embeddings)\n",
    "model.tie_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9a3df916-7300-4ac2-a9b7-01954c187512",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained( os.path.join( trained_model_folder, selected_model_dropdown.value + \"_prefixed\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7002a67-4eb3-47d4-8973-09b98336b68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_index = -1\n",
    "max_value = -20000\n",
    "for i in range(len(tokenizer)):\n",
    "    if result.logits[-1][i].detach().numpy() > max_value:\n",
    "        max_value = result.logits[-1][i].detach().numpy()\n",
    "        max_index = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82783222-25a9-4f04-8a9d-5acc20df3ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2140da-03bb-4d5d-b7a9-e1a740fdc98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode([max_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b16a8eb-bc75-49d0-8e30-383dbde01fdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[GEN 1:1_a] [GEN 1:1_b] Afterward, He looked up and saw a young man dressed in a white robe, as'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output = model.generate( tokenizer.encode(\"[GEN 1:1_a][GEN 1:1_b]\", return_tensors='pt'),do_sample=True,max_length=20,pad_token_id=model.config.eos_token_id, top_k=50, top_p=.95 )\n",
    "tokenizer.decode( model_output[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ea34afad-d00d-4f93-89f7-50071539f802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[GEN 1:1_a] [GEN 1:1_b] And the LORD said to Moses, “Tell Aaron, ‘Stretch out your hand over the waters of Meribah, for the LORD has sent a message concerning you.’” So Aaron stretched out his hand over the waters of Meribah, and the LORD sent a message over the waters of Meribah. waters never again spanned the Red Sea. Flavoringities of theiph, the flies, and the creatures that inhabited the ground covered the Red Sea. Flavoringities of theiph, the flies, and the creatures that inhabited the ground covered the Red Sea. Flavoringities of the creatures that inhabited the ground were so deep that the water had no flow. Flavoringities of the creatures that inhabited the ground were so deep that the water had no flow. Flavoringities of the creatures that inhabited the ground were so deep that the water had no flow. Flavoringities of the creatures that inhabited the ground were so deep that the water had no flow. Flavoringities of'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output = model.generate( tokenizer.encode(\"[GEN 1:1_a][GEN 1:1_b]\", return_tensors='pt'),do_sample=True,max_length=200,pad_token_id=model.config.eos_token_id, top_k=1, top_p=.95 )\n",
    "tokenizer.decode( model_output[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d74255c7-071a-4508-ba0e-0e6e92dc5311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[GEN 1:3_a] [GEN 1:3_b] And the LORD said to Moses, “Tell Aaron, ‘Stretch out your hand over the waters of Meribah, for the LORD has sent a message concerning you.’” So Aaron stretched out his hand over the waters of Merib [MAT 18:14_b] etheless, the LORD did not listen to him, and the LORD did not destroy the people. Instead, the LORD stirred up the waters of Meribah and the people of the land went down to the springs.etheless, the LORD did not destroy them.asaptions of God came up, and the people of the land rejoiced.asaptions of God came up, and the LORD didrail over the people.asaptions of God came up, and the LORD did not destroy them.asaptions of God came up, and the LORD did not destroy them.asaptions of God came up, and the LORD did not destroy them.asaptions of God came up, and the LORD did not destroy them.asa'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output = model.generate( tokenizer.encode(\"[GEN 1:3_a][GEN 1:3_b]\", return_tensors='pt'),do_sample=True,max_length=200,pad_token_id=model.config.eos_token_id, top_k=1, top_p=.95 )\n",
    "tokenizer.decode( model_output[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff36fb99-5b87-41f9-961b-a507f3d89975",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
