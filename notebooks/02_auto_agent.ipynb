{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autonomous Agent Example\n",
    "\n",
    "In this notebook, we instantiate an autonomous agent with an in-memory vectorstore. The agent is theoretically able to read the bibles.csv file in this repo, but your mileage may vary, and it probably makes sense to try turning bibles.csv into a vectorstore that the agent has access to as a tool.\n",
    "\n",
    "## Paths to pursue\n",
    "\n",
    "- [ ] Try to get the agent to read the bibles.csv file in this repo\n",
    "- [ ] Try to get the agent to read a vectorstore that you create from bibles.csv\n",
    "- [ ] Try to get the agent to identify translation rules from the Bibles in the eBible corpus (see [permissively licensed Bibles](https://github.com/sil-ai/sil-microsoft-hackathon-2023/blob/main/data/permissive_licensed_translations.csv))\n",
    "- [ ] Try to get agents interacting in some kind of adversarial loop, where one agent is translating, and another is evaluating the translation, and the first agent is trying to improve its translation based on the evaluation\n",
    "\n",
    "## Resources\n",
    "\n",
    "- [AutoGPT agents in LangChain](https://python.langchain.com/docs/use_cases/more/agents/autonomous_agents/autogpt)\n",
    "- [Combine agents with vectorstores](https://python.langchain.com/docs/modules/agents/how_to/agent_vectorstore)\n",
    "- [LanceDB vectorstore (kind of like a NoSQL vectorstore)](https://python.langchain.com/docs/integrations/vectorstores/lancedb) & [API ref](https://api.python.langchain.com/en/latest/vectorstores/langchain.vectorstores.lancedb.LanceDB.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "zsh:1: /usr/local/bin/pip: bad interpreter: /usr/local/opt/python@3.10/bin/python3.10: no such file or directory\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade langchain faiss-cpu langchain_experimental -qq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import getpass, os \n",
    "secret_key = getpass.getpass('Enter OpenAI secret key: ') \n",
    "os.environ['OPENAI_API_KEY'] = secret_key\n",
    "\n",
    "# NOTE: For local model testing, use the following\n",
    "# os.environ['OPENAI_API_KEY'] = 'empty'\n",
    "# os.environ['OPENAI_API_BASE'] = 'http://192.168.1.76:8081/v1/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import Tool\n",
    "from langchain.tools.file_management.write import WriteFileTool\n",
    "from langchain.tools.file_management.read import ReadFileTool\n",
    "\n",
    "\n",
    "\n",
    "tools = [\n",
    "    WriteFileTool(),\n",
    "    ReadFileTool(),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.docstore import InMemoryDocstore\n",
    "from langchain.embeddings import HuggingFaceEmbeddings, OpenAIEmbeddings\n",
    "\n",
    "# Define your embedding model and set embedding size\n",
    "\n",
    "# embeddings_model = OpenAIEmbeddings()\n",
    "# embedding_size = 1536 # for openai embeddings\n",
    "\n",
    "embeddings_model = HuggingFaceEmbeddings()\n",
    "embedding_size = 768 # for huggingface embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the vectorstore as empty\n",
    "import faiss\n",
    "\n",
    "index = faiss.IndexFlatL2(embedding_size)\n",
    "vectorstore = FAISS(embeddings_model.embed_query, index, InMemoryDocstore({}), {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.autonomous_agents import AutoGPT\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory.chat_message_histories import FileChatMessageHistory\n",
    "\n",
    "agent = AutoGPT.from_llm_and_tools(\n",
    "    ai_name=\"Tom\",\n",
    "    ai_role=\"Assistant\",\n",
    "    tools=tools,\n",
    "    llm=ChatOpenAI(temperature=0, verbose=True),\n",
    "    memory=vectorstore.as_retriever(),\n",
    "    chat_history_memory=FileChatMessageHistory(\"chat_history.txt\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"thoughts\": {\n",
      "    \"text\": \"Since I have already reviewed my previous actions and checked for new tasks or objectives, I can move on to the next step. One of my goals is to translate some Bible verses into Spanish. To do this, I will need to access the Bible verses from the file 'bibles.csv' and then translate them using an online translation tool.\",\n",
      "    \"reasoning\": \"By accessing the Bible verses from the file and using an online translation tool, I can efficiently translate them into Spanish.\",\n",
      "    \"plan\": \"- Read the 'bibles.csv' file to access the Bible verses\\n- Use an online translation tool to translate the verses into Spanish\",\n",
      "    \"criticism\": \"I should ensure that the online translation tool I use is reliable and accurate to ensure the accuracy of the translations.\",\n",
      "    \"speak\": \"I will read the 'bibles.csv' file to access the Bible verses and then use an online translation tool to translate them into Spanish.\"\n",
      "  },\n",
      "  \"command\": {\n",
      "    \"name\": \"read_file\",\n",
      "    \"args\": {\n",
      "      \"file_path\": \"../data/bibles.csv\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "{\n",
      "  \"thoughts\": {\n",
      "    \"text\": \"Since I don't have any specific tasks at the moment, I can review my past actions and evaluate my performance. This will help me identify any areas for improvement and refine my approach.\",\n",
      "    \"reasoning\": \"By reflecting on my past decisions and strategies, I can gain insights into my performance and make adjustments for better efficiency and effectiveness.\",\n",
      "    \"plan\": \"- Review past actions\\n- Analyze performance\\n- Identify areas for improvement\\n- Refine approach\",\n",
      "    \"criticism\": \"I need to ensure that I am continuously evaluating my performance and making necessary adjustments. It's important to be proactive in improving my decision-making and task execution.\",\n",
      "    \"speak\": \"I will now review my past actions and evaluate my performance to identify areas for improvement.\"\n",
      "  },\n",
      "  \"command\": {\n",
      "    \"name\": \"finish\",\n",
      "    \"args\": {\n",
      "      \"response\": \"I have finished reviewing my past actions and evaluating my performance.\"\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'I have finished reviewing my past actions and evaluating my performance.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run([\"translate some Bible verses found in ../data/bibles.csv into Spanish\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
